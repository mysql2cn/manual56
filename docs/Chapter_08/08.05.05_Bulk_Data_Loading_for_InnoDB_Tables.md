#  8.5.5 Bulk Data Loading for InnoDB Tables

### 8.5.5 Bulk Data Loading for InnoDB Tables

下面的性能建议，是针对[Section 8.2.3.1, “Optimizing INSERT Statements”](TODO)的一个补充。

* 当你想InnoDB中导入大量数据的时候，禁用aotocommit模式。因为autocommit会在每个insert语句中，向磁盘刷入日志。可以通过在开头增加SET autocommit以及在结尾增加COMMIT来实现：

	```
	SET autocommit=0;
	... SQL import statements ...
	COMMIT;
	```

mysqldump指定参数--opt可以创建一个dump files，能实现向InnoDB中快速导入数据，并且不用增加SET autocommit和COMMIT语句。

* 如果你在非主键索引上存在UNIQUE约束，你可以尝试在导入的session中关掉唯一性检查：

	```
	SET unique_checks=0;
	... SQL import statements ...
	SET unique_checks=1;
	```

对于大表，这样会节省大量的磁盘I/O。因为InnoDB可以利用他的change buffer来缓存对非主键索引的修改。但是一定要确保数据中没有重复的keys。

* 如果你的表中存在FOREIGN KEY约束的话，你可以通过在导入的session中关闭外键检查，来进行加速：

	```
	SET foreign_key_checks=0;
	... SQL import statements ...
	SET foreign_key_checks=1;
	For big tables, this can save a lot of disk I/O.
	```

 对于大表来说，这样可以节约大量的I/O。
 
* 如果你要插入大量的数据的话，使用multiple-row INSERT来减少插入时的开销：

	```
	INSERT INTO yourtable VALUES (1,2), (5,5), ...;
	```

  这个tip对于所有表的插入操作都是有效的，不限于InnoDB
 
* 当大量插入的表中，包括自增长列的时候，将innodb_autoinc_lock_mode设置为2，而不是默认值1.参考[See Section 14.8.6, “AUTO_INCREMENT Handling in InnoDB” for details](TODO)。

* 当插入大量数据的时候，按照主键顺序的方式插入更快。InnoDB使用聚簇索引，这种索引在数据按照主键顺序使用的时候更高效。按照主键顺序插入这种方式，对于不能完全放入buffer pool中的表尤为重要。

* 按照如下步骤，可以在按照InnoDB全文索引加载数据的时候，获取最佳性能：

	* 在创建表的时候，创建名称为FTS_DOC_ID的列，使用的数据格式为BIGINT UNSIGNED NOT NULL，并且在之上创建一个唯一索引FTS_DOC_ID_INDEX，例如：
	
	```
	CREATE TABLE t1 (
	FTS_DOC_ID BIGINT unsigned NOT NULL AUTO_INCREMENT,
	title varchar(255) NOT NULL DEFAULT ”,
	text mediumtext NOT NULL,
	PRIMARY KEY (`FTS_DOC_ID`)
	) ENGINE=InnoDB DEFAULT CHARSET=latin1;
	CREATE UNIQUE INDEX FTS_DOC_ID_INDEX on t1(FTS_DOC_ID);
	```
	* 向表中加载数据
	* 在数据加载完成后，创建全文索引

	> NOTE：
	>
	> 创建完成后，向表添加数据的过程中，需要保证每当全文索引所包含列更新或者插入数据的时候，FTS_DOC_ID列都需要自增。如果你不在创建表的时候添加FTS_DOC_ID这列，InnoDB会默认给你创建一个隐藏列并自动更新。但是这样会导致每次插入或更新时，表都会重建，对性能带来很大的影响。